from flask import Flask, request, jsonify
import openai
import os
from dotenv import load_dotenv
from flask_cors import CORS

# Charger les variables d'environnement et configurer la cl√© API
load_dotenv()
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Historique de conversation avec le message syst√®me initial
conversation_history = [
    {"role": "system", "content": "Tu es un expert en cuisine. Tu ne r√©ponds qu'aux questions sur la cuisine."}
]

def est_question_cuisine(user_input):
    """
    V√©rifie avec GPT si la question est li√©e √† la cuisine.
    R√©pond uniquement par 'OUI' ou 'NON' sans explications.
    """
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": (
                    "Tu es un classificateur de questions. Pour chaque question, r√©ponds uniquement par 'OUI' "
                    "si la question concerne la cuisine (cuisine, ingr√©dients, etc...), ou par 'NON' dans le cas contraire. Ne donne aucune explication."
                )
            },
            {"role": "user", "content": user_input}
        ]
    )
    classification = response.choices[0].message.content.strip().upper()
    print("Classification brute:", classification)  # Ligne de debug pour v√©rifier la r√©ponse
    return "OUI" in classification

def chatbot_response(user_input):
    """
    G√®re la r√©ponse du chatbot :
      - V√©rifie si la question concerne la cuisine.
      - Si oui, ajoute le message √† l'historique et interroge l'API OpenAI.
      - Sinon, renvoie un message par d√©faut.
    """
    global conversation_history

    # V√©rifier si la question est li√©e √† la cuisine
    if not est_question_cuisine(user_input):
        return "Je ne parle que de cuisine ! Pose-moi une question sur les plats, les recettes ou les ingr√©dients. üòä"
    
    # Ajouter le message de l'utilisateur √† l'historique
    conversation_history.append({"role": "user", "content": user_input})
    
    # Garder le message syst√®me et les 10 derniers √©changes
    conversation_history = [conversation_history[0]] + conversation_history[-10:]
    
    # Appeler l'API OpenAI pour obtenir la r√©ponse
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=conversation_history
    )
    
    # Extraire la r√©ponse du bot
    bot_reply = response.choices[0].message.content.strip()
    print(bot_reply)  # Ligne de debug pour v√©rifier la r√©ponse
    
    # Ajouter la r√©ponse √† l'historique
    conversation_history.append({"role": "assistant", "content": bot_reply})
    
    return bot_reply

# Initialisation de l'application Flask
app = Flask(__name__)
CORS(app)  # Autoriser les requ√™tes cross-origin

@app.route('/chat', methods=['POST'])
def chat_endpoint():
    data = request.get_json()
    if not data or 'message' not in data:
        return jsonify({"error": "Message non fourni"}), 400

    user_input = data['message']
    answer = chatbot_response(user_input)
    return jsonify({"response": answer})

if __name__ == '__main__':
    app.run(debug=True)
